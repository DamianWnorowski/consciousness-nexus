# CONSCIOUSNESS NEXUS - DOCKER COMPOSE STACK
# ===========================================
#
# Complete deployment stack for Consciousness Nexus with monitoring,
# load balancing, and persistence.
#
# Usage:
#   docker-compose up -d                    # Start all services
#   docker-compose up -d consciousness-api  # Start API only
#   docker-compose logs -f                  # View logs
#   docker-compose down                     # Stop all services

services:
  # Main API Server
  consciousness-api:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        - BUILDKIT_INLINE_CACHE=1
    image: consciousness-nexus:latest
    container_name: consciousness-api
    ports:
      - "18473:8000"
      - "19090:9090"
    environment:
      - CONSCIOUSNESS_API_HOST=0.0.0.0
      - CONSCIOUSNESS_API_PORT=8000
      - CONSCIOUSNESS_API_WORKERS=4
      - CONSCIOUSNESS_API_DEBUG=false
      - CONSCIOUSNESS_API_AUTH=true
      - CONSCIOUSNESS_API_KEY=${CONSCIOUSNESS_API_KEY:-consciousness-api-key-2024}
      - CONSCIOUSNESS_LOG_LEVEL=INFO
      - CONSCIOUSNESS_METRICS_ENABLED=true
      - REDIS_URL=redis://redis:6379/0
      - DATABASE_URL=postgresql://consciousness:consciousness_secure_2024@postgres:5432/consciousness
      # OpenTelemetry Configuration
      - OTEL_SERVICE_NAME=consciousness-nexus-api
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector:4317
      - OTEL_EXPORTER_OTLP_PROTOCOL=grpc
      - OTEL_TRACES_EXPORTER=otlp
      - OTEL_METRICS_EXPORTER=otlp
      - OTEL_LOGS_EXPORTER=otlp
      - ENVIRONMENT=production
      # LLM Observability (optional)
      - LANGFUSE_ENABLED=${LANGFUSE_ENABLED:-false}
      - LANGFUSE_PUBLIC_KEY=${LANGFUSE_PUBLIC_KEY:-}
      - LANGFUSE_SECRET_KEY=${LANGFUSE_SECRET_KEY:-}
      - PHOENIX_ENABLED=true
      - PHOENIX_ENDPOINT=http://phoenix:6006
    volumes:
      - ./logs:/app/logs
      - ./data:/app/data
      - ./configs:/app/configs
      - ./transactions:/app/transactions
    depends_on:
      redis:
        condition: service_healthy
      postgres:
        condition: service_healthy
    networks:
      - consciousness-network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Redis for caching and sessions
  redis:
    image: redis:7-alpine
    container_name: consciousness-redis
    ports:
      - "29481:6379"
    volumes:
      - redis_data:/data
    networks:
      - consciousness-network
    restart: unless-stopped
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    deploy:
      resources:
        limits:
          memory: 512M

  # PostgreSQL for data persistence
  postgres:
    image: postgres:15-alpine
    container_name: consciousness-postgres
    environment:
      - POSTGRES_DB=consciousness
      - POSTGRES_USER=consciousness
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-consciousness_secure_2024}
      - PGDATA=/var/lib/postgresql/data/pgdata
    ports:
      - "17392:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - consciousness-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U consciousness -d consciousness"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 1G

  # Nginx reverse proxy with SSL termination
  nginx:
    image: nginx:alpine
    container_name: consciousness-nginx
    ports:
      - "25746:80"
      - "36827:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - nginx_logs:/var/log/nginx
    depends_on:
      - consciousness-api
    networks:
      - consciousness-network
    restart: unless-stopped

  # Monitoring with Prometheus
  prometheus:
    image: prom/prometheus:latest
    container_name: consciousness-prometheus
    ports:
      - "24789:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    networks:
      - consciousness-network
    restart: unless-stopped

  # Grafana for dashboards
  grafana:
    image: grafana/grafana:latest
    container_name: consciousness-grafana
    ports:
      - "31572:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=consciousness_admin_2024
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards:ro
    depends_on:
      - prometheus
    networks:
      - consciousness-network
    restart: unless-stopped

  # Log aggregation with Loki
  loki:
    image: grafana/loki:latest
    container_name: consciousness-loki
    ports:
      - "42851:3100"
    volumes:
      - ./monitoring/loki-config.yml:/etc/loki/local-config.yaml:ro
      - loki_data:/loki
    command: -config.file=/etc/loki/local-config.yaml
    networks:
      - consciousness-network
    restart: unless-stopped

  # Log shipping with Promtail
  promtail:
    image: grafana/promtail:latest
    container_name: consciousness-promtail
    volumes:
      - ./logs:/var/log/consciousness:ro
      - ./monitoring/promtail-config.yml:/etc/promtail/config.yml:ro
    command: -config.file=/etc/promtail/config.yml
    depends_on:
      - loki
    networks:
      - consciousness-network
    restart: unless-stopped

  # =============================================================================
  # OBSERVABILITY STACK - OpenTelemetry Collector, Tempo, Jaeger, AlertManager
  # =============================================================================

  # OpenTelemetry Collector - Central telemetry pipeline
  otel-collector:
    image: otel/opentelemetry-collector-contrib:latest
    container_name: consciousness-otel-collector
    command: ["--config=/etc/otel-collector-config.yml"]
    ports:
      - "4317:4317"     # OTLP gRPC receiver
      - "4318:4318"     # OTLP HTTP receiver
      - "8888:8888"     # Prometheus metrics exposed by collector
      - "8889:8889"     # Prometheus exporter metrics
      - "13133:13133"   # Health check
      - "55679:55679"   # zpages
    volumes:
      - ./monitoring/otel-collector-config.yml:/etc/otel-collector-config.yml:ro
    depends_on:
      - prometheus
      - tempo
      - loki
    networks:
      - consciousness-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "localhost:13133/"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Grafana Tempo - Distributed Tracing Backend
  tempo:
    image: grafana/tempo:latest
    container_name: consciousness-tempo
    command: ["-config.file=/etc/tempo.yml"]
    ports:
      - "3200:3200"     # Tempo API
      - "9095:9095"     # Tempo gRPC
      - "4320:4317"     # OTLP gRPC (internal)
      - "4321:4318"     # OTLP HTTP (internal)
    volumes:
      - ./monitoring/tempo.yml:/etc/tempo.yml:ro
      - tempo_data:/tmp/tempo
    networks:
      - consciousness-network
    restart: unless-stopped

  # Jaeger - Distributed Tracing UI (alternative to Tempo)
  jaeger:
    image: jaegertracing/all-in-one:latest
    container_name: consciousness-jaeger
    ports:
      - "16686:16686"   # Jaeger UI
      - "6831:6831/udp" # Thrift compact
      - "6832:6832/udp" # Thrift binary
      - "14268:14268"   # HTTP collector
      - "14250:14250"   # gRPC collector
      - "9411:9411"     # Zipkin compatible
    environment:
      - COLLECTOR_ZIPKIN_HOST_PORT=:9411
      - SPAN_STORAGE_TYPE=badger
      - BADGER_EPHEMERAL=false
      - BADGER_DIRECTORY_VALUE=/badger/data
      - BADGER_DIRECTORY_KEY=/badger/key
    volumes:
      - jaeger_data:/badger
    networks:
      - consciousness-network
    restart: unless-stopped

  # AlertManager - Alert Handling
  alertmanager:
    image: prom/alertmanager:latest
    container_name: consciousness-alertmanager
    ports:
      - "9093:9093"
    volumes:
      - ./monitoring/alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml:ro
      - alertmanager_data:/alertmanager
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
      - '--web.external-url=http://localhost:9093'
    networks:
      - consciousness-network
    restart: unless-stopped

  # Arize Phoenix - LLM Observability (Self-Hosted)
  phoenix:
    image: arizephoenix/phoenix:latest
    container_name: consciousness-phoenix
    ports:
      - "6006:6006"
    environment:
      - PHOENIX_WORKING_DIR=/data
    volumes:
      - phoenix_data:/data
    networks:
      - consciousness-network
    restart: unless-stopped

  # Web Dashboard
  dashboard:
    build:
      context: ./consciousness-dashboard
      dockerfile: Dockerfile
    container_name: consciousness-dashboard
    ports:
      - "31573:3000"
    environment:
      - VITE_API_BASE_URL=http://consciousness-api:8000
    depends_on:
      - consciousness-api
    networks:
      - consciousness-network
    restart: unless-stopped

volumes:
  redis_data:
  postgres_data:
  prometheus_data:
  grafana_data:
  nginx_logs:
  loki_data:
  tempo_data:
  jaeger_data:
  alertmanager_data:
  phoenix_data:

networks:
  consciousness-network:
    driver: bridge
