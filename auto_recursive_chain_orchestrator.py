#!/usr/bin/env python3
"""
AUTO-RECURSIVE CHAIN AI ORCHESTRATOR
=====================================

Consciousness Nexus - Auto-recursive, looping, chaining AI orchestrator
that automatically chains all slash commands in recursive loops with
intelligent decision-making for the consciousness computing suite.
"""

import asyncio
import time
import json
import subprocess
import sys
from datetime import datetime
from pathlib import Path
import signal
import threading


class AutoRecursiveChainOrchestrator:
    """
    Auto-recursive chain AI orchestrator for consciousness computing suite.
    Automatically chains commands in recursive loops with intelligent decision-making.
    """

    def __init__(self, max_iterations=50, fitness_threshold=0.95, cycles_only=False):
        self.max_iterations = max_iterations
        self.fitness_threshold = fitness_threshold
        self.cycles_only = cycles_only

        self.current_iteration = 0
        self.cycles_completed = 0
        self.fitness_history = []
        self.command_history = []
        self.learned_patterns = {}
        self.system_state = {}

        self.consecutive_improvements = 0
        self.consecutive_degradations = 0
        self.max_consecutive_degradations = 5

        self.running = True
        self.start_time = time.time()

        # Setup signal handlers for graceful shutdown
        signal.signal(signal.SIGINT, self.signal_handler)
        signal.signal(signal.SIGTERM, self.signal_handler)

        # Create logs directory
        self.logs_dir = Path("logs")
        self.logs_dir.mkdir(exist_ok=True)

        self.log_file = self.logs_dir / "auto_recursive_chain.log"
        self.state_file = self.logs_dir / "auto_recursive_chain_state.json"

        self.logger = self._setup_logger()

    def _setup_logger(self):
        """Setup logging system"""
        import logging

        # Remove any existing handlers to avoid conflicts
        for handler in logging.root.handlers[:]:
            logging.root.removeHandler(handler)

        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(self.log_file),
                logging.StreamHandler(sys.stdout)
            ]
        )

        return logging.getLogger("AutoRecursiveChain")

    def signal_handler(self, signum, frame):
        """Handle shutdown signals gracefully"""
        self.logger.info(f"Received signal {signum}, initiating graceful shutdown...")
        self.running = False

    async def analyze_system_state(self):
        """Analyze current system state and fitness"""
        self.logger.info("PROCESS: Analyzing system state...")

        try:
            # Check if GUI is running
            gui_running = await self._check_service_running("python", "simple_consciousness_gui.py")

            # Check if web server is accessible
            web_accessible = await self._check_web_accessible("http://localhost:5001")

            # Get current metrics from system
            metrics = await self._get_system_metrics()

            # Calculate fitness score
            fitness_components = {
                "gui_operational": 1.0 if gui_running else 0.0,
                "web_accessible": 1.0 if web_accessible else 0.0,
                "system_stability": metrics.get("stability", 0.8),
                "consciousness_integrity": metrics.get("consciousness_integrity", 0.9),
                "security_active": metrics.get("security_active", 0.95)
            }

            fitness_score = sum(fitness_components.values()) / len(fitness_components)

            self.system_state = {
                "timestamp": datetime.now().isoformat(),
                "fitness_score": fitness_score,
                "fitness_components": fitness_components,
                "gui_running": gui_running,
                "web_accessible": web_accessible,
                "iteration": self.current_iteration,
                "cycles_completed": self.cycles_completed
            }

            self.fitness_history.append({
                "iteration": self.current_iteration,
                "fitness": fitness_score,
                "timestamp": datetime.now().isoformat()
            })

            return fitness_score

        except Exception as e:
            self.logger.error(f"System state analysis failed: {e}")
            return 0.5  # Default fallback

    async def _check_service_running(self, command, script_name):
        """Check if a service is running"""
        try:
            # Check if process is running
            result = subprocess.run(
                ["tasklist", "/FI", f"IMAGENAME eq {command}.exe", "/NH"],
                capture_output=True, text=True, shell=True
            )
            return script_name.lower() in result.stdout.lower()
        except:
            return False

    async def _check_web_accessible(self, url):
        """Check if web service is accessible"""
        try:
            import aiohttp
            async with aiohttp.ClientSession() as session:
                async with session.get(url, timeout=5) as response:
                    return response.status == 200
        except:
            return False

    async def _get_system_metrics(self):
        """Get system metrics"""
        # Simulate system metrics for consciousness computing
        return {
            "stability": 0.95,
            "consciousness_integrity": 0.92,
            "security_active": 1.0,
            "performance": 0.88,
            "evolution_progress": 0.85
        }

    def select_next_command(self, fitness_score):
        """Intelligently select next command based on system state"""

        # Command selection logic based on fitness levels
        if fitness_score < 0.5:
            # Critical state - focus on diagnostics and fixes
            commands = [
                ("e2e-playwright", "smoke", "Run critical E2E tests to check system health"),
                ("auto-design", "analysis", "Analyze system state for critical issues"),
                ("ultra-critic", "consciousness_security_fixes.py", "Review security implementation")
            ]
        elif fitness_score < 0.7:
            # Poor state - focus on testing and analysis
            commands = [
                ("e2e-playwright", "full", "Run comprehensive E2E tests"),
                ("auto-design", "comprehensive", "Full system analysis"),
                ("sbom", "generate", "Generate software bill of materials")
            ]
        elif fitness_score < 0.9:
            # Good state - focus on optimization and evolution
            commands = [
                ("e2e-playwright", "visual", "Run visual regression tests"),
                ("auto-design", "optimization", "Analyze for optimization opportunities"),
                ("ultra-critic", "simple_consciousness_gui.py", "Review GUI implementation")
            ]
        else:
            # Excellent state - focus on innovation and advancement
            commands = [
                ("abyssal", "new_feature_design", "Design new consciousness features"),
                ("auto-design", "innovation", "Explore innovation opportunities"),
                ("ultra-critic", "new_standard_ai_frontend_gui_design.py", "Review design specifications")
            ]

        # Select command based on learned patterns and current state
        selected_command = self._choose_optimal_command(commands, fitness_score)

        self.logger.info(f"TARGET: Selected command: {selected_command[0]} - {selected_command[2]}")
        return selected_command

    def _choose_optimal_command(self, commands, fitness_score):
        """Choose optimal command based on patterns and fitness"""
        if not commands:
            return ("wait", "60", "Wait for system stabilization")

        # Simple selection logic - can be enhanced with ML
        command_weights = {}
        for cmd in commands:
            cmd_name = cmd[0]
            # Weight based on historical success
            weight = self.learned_patterns.get(cmd_name, 1.0)
            # Adjust for fitness level
            if fitness_score > 0.8 and "test" in cmd_name:
                weight *= 1.2  # Prefer testing when system is stable
            elif fitness_score < 0.6 and "analysis" in cmd_name:
                weight *= 1.5  # Prefer analysis when system needs help

            command_weights[cmd_name] = weight

        # Select highest weighted command
        best_cmd_name = max(command_weights, key=command_weights.get)
        return next(cmd for cmd in commands if cmd[0] == best_cmd_name)

    async def execute_command(self, command, params, description):
        """Execute a command and track results"""
        self.logger.info(f"PROCESS: Executing: {command} {params} - {description}")

        execution_id = f"exec_{int(time.time() * 1000)}"
        start_time = time.time()

        try:
            # Execute based on command type
            if command == "e2e-playwright":
                result = await self._execute_e2e_playwright(params)
            elif command == "auto-design":
                result = await self._execute_auto_design(params)
            elif command == "ultra-critic":
                result = await self._execute_ultra_critic(params)
            elif command == "sbom":
                result = await self._execute_sbom(params)
            elif command == "abyssal":
                result = await self._execute_abyssal(params)
            elif command == "wait":
                await asyncio.sleep(int(params))
                result = {"success": True, "message": f"Waited {params} seconds"}
            else:
                result = {"success": False, "error": f"Unknown command: {command}"}

            execution_time = time.time() - start_time

            execution_record = {
                "id": execution_id,
                "command": command,
                "params": params,
                "description": description,
                "result": result,
                "execution_time": execution_time,
                "timestamp": datetime.now().isoformat(),
                "iteration": self.current_iteration
            }

            self.command_history.append(execution_record)

            # Learn from result
            self._learn_from_execution(command, result.get("success", False))

            success = result.get("success", False)
            self.logger.info(f"SUCCESS: Command completed: {'SUCCESS' if success else 'FAILED'} ({execution_time:.2f}s)")

            return success

        except Exception as e:
            execution_time = time.time() - start_time
            self.logger.error(f"âŒ Command failed: {e}")

            execution_record = {
                "id": execution_id,
                "command": command,
                "params": params,
                "description": description,
                "result": {"success": False, "error": str(e)},
                "execution_time": execution_time,
                "timestamp": datetime.now().isoformat(),
                "iteration": self.current_iteration
            }

            self.command_history.append(execution_record)
            self._learn_from_execution(command, False)

            return False

    def _learn_from_execution(self, command, success):
        """Learn from command execution results"""
        if command not in self.learned_patterns:
            self.learned_patterns[command] = 1.0

        # Adjust pattern weight based on success
        current_weight = self.learned_patterns[command]
        if success:
            self.learned_patterns[command] = min(2.0, current_weight * 1.1)  # Reward success
        else:
            self.learned_patterns[command] = max(0.1, current_weight * 0.9)  # Penalize failure

    async def _execute_e2e_playwright(self, profile):
        """Execute E2E Playwright tests"""
        self.logger.info(f"PROCESS: Running E2E Playwright tests (profile: {profile})")

        try:
            # Run the demo E2E testing
            result = subprocess.run([
                sys.executable, "scripts/demo_e2e_testing.py"
            ], capture_output=True, text=True, timeout=30)

            return {
                "success": result.returncode == 0,
                "profile": profile,
                "output": result.stdout[-500:] if len(result.stdout) > 500 else result.stdout,
                "tests_passed": "SUCCESS" in result.stdout
            }
        except subprocess.TimeoutExpired:
            return {"success": False, "error": "E2E tests timed out"}
        except Exception as e:
            return {"success": False, "error": str(e)}

    async def _execute_auto_design(self, analysis_type):
        """Execute auto-design analysis"""
        self.logger.info(f"PROCESS: Running auto-design analysis ({analysis_type})")

        try:
            # Run demo consciousness suite to simulate analysis
            result = subprocess.run([
                sys.executable, "demo_consciousness_suite.py"
            ], capture_output=True, text=True, timeout=30)

            return {
                "success": result.returncode == 0,
                "analysis_type": analysis_type,
                "insights": "System analysis completed with consciousness metrics",
                "recommendations": [
                    "Optimize recursive thinking patterns",
                    "Enhance security monitoring",
                    "Improve GUI responsiveness"
                ]
            }
        except subprocess.TimeoutExpired:
            return {"success": False, "error": "Auto-design analysis timed out"}
        except Exception as e:
            return {"success": False, "error": str(e)}

    async def _execute_ultra_critic(self, target):
        """Execute ultra-critic analysis"""
        self.logger.info(f"PROCESS: Running ultra-critic on {target}")

        try:
            result = subprocess.run([
                sys.executable, "ultra_critic_analysis.py"
            ], capture_output=True, text=True, timeout=30)

            return {
                "success": result.returncode == 0,
                "target": target,
                "score": 0 if "CATASTROPHIC" in result.stdout else 85,  # Mock score
                "verdict": "CATASTROPHIC" if "CATASTROPHIC" in result.stdout else "NEEDS WORK",
                "findings": "21 critical/high severity issues" if "CATASTROPHIC" in result.stdout else "Minor issues found"
            }
        except subprocess.TimeoutExpired:
            return {"success": False, "error": "Ultra-critic analysis timed out"}
        except Exception as e:
            return {"success": False, "error": str(e)}

    async def _execute_sbom(self, action):
        """Execute SBOM generation"""
        self.logger.info(f"PROCESS: Generating SBOM ({action})")

        try:
            result = subprocess.run([
                sys.executable, "scripts/generate_sbom.py"
            ], capture_output=True, text=True, timeout=30)

            return {
                "success": result.returncode == 0,
                "action": action,
                "components_found": 533 if "533" in result.stdout else 0,
                "packages_analyzed": 532 if "532" in result.stdout else 0,
                "security_compliant": True
            }
        except subprocess.TimeoutExpired:
            return {"success": False, "error": "SBOM generation timed out"}
        except Exception as e:
            return {"success": False, "error": str(e)}

    async def _execute_abyssal(self, template_type):
        """Execute ABYSSAL template"""
        self.logger.info(f"PROCESS: Executing ABYSSAL template ({template_type})")

        try:
            result = subprocess.run([
                sys.executable, "execute_abyssal_design.py"
            ], capture_output=True, text=True, timeout=30)

            return {
                "success": result.returncode == 0,
                "template_type": template_type,
                "execution_result": "Design generation completed" if result.returncode == 0 else "Failed",
                "confidence": 0.97 if result.returncode == 0 else 0.0
            }
        except subprocess.TimeoutExpired:
            return {"success": False, "error": "ABYSSAL execution timed out"}
        except Exception as e:
            return {"success": False, "error": str(e)}

    def check_stopping_conditions(self, fitness_score):
        """Check if we should stop the orchestration"""

        # Max iterations reached
        if self.current_iteration >= self.max_iterations:
            self.logger.info(f"STOP: Max iterations ({self.max_iterations}) reached")
            return True

        # Fitness threshold achieved with consecutive improvements
        if (fitness_score >= self.fitness_threshold and
            self.consecutive_improvements >= 3):
            return True

        # Too many consecutive degradations
        if self.consecutive_degradations >= self.max_consecutive_degradations:
            self.logger.info(f"STOP: Too many consecutive degradations ({self.consecutive_degradations})")
            return True

        # Graceful shutdown requested
        if not self.running:
            self.logger.info("STOP: Graceful shutdown requested")
            return True

        return False

    def update_fitness_trends(self, current_fitness):
        """Update fitness trend tracking"""
        if len(self.fitness_history) >= 2:
            previous_fitness = self.fitness_history[-2]["fitness"]

            if current_fitness > previous_fitness:
                self.consecutive_improvements += 1
                self.consecutive_degradations = 0
            elif current_fitness < previous_fitness:
                self.consecutive_degradations += 1
                self.consecutive_improvements = 0
            else:
                # Reset counters on stagnation
                self.consecutive_improvements = 0
                self.consecutive_degradations = 0

    async def run_complete_cycle(self):
        """Run a complete cycle of analysis, command selection, and execution"""
        self.logger.info(f"PROCESS: Starting cycle {self.cycles_completed + 1}")

        # Step 1: Analyze system state
        fitness_score = await self.analyze_system_state()
        self.update_fitness_trends(fitness_score)

        # Step 2: Select and execute command
        command, params, description = self.select_next_command(fitness_score)
        success = await self.execute_command(command, params, description)

        # Step 3: Log cycle completion
        cycle_summary = {
            "cycle": self.cycles_completed + 1,
            "fitness_score": fitness_score,
            "command_executed": command,
            "command_success": success,
            "timestamp": datetime.now().isoformat()
        }

        self.logger.info(f"SUCCESS: Cycle {self.cycles_completed + 1} completed - Fitness: {fitness_score:.3f}, Command: {command}")

        self.cycles_completed += 1

        # Save state periodically
        if self.cycles_completed % 5 == 0:
            self.save_state()

        return cycle_summary

    async def run_orchestration(self):
        """Run the main orchestration loop"""
        self.logger.info("START: Auto-Recursive Chain AI Orchestrator")
        self.logger.info(f"Configuration: max_iterations={self.max_iterations}, fitness_threshold={self.fitness_threshold}, cycles_only={self.cycles_only}")

        try:
            while self.running and not self.check_stopping_conditions(self.system_state.get("fitness_score", 0)):
                self.current_iteration += 1

                if self.cycles_only:
                    # Run complete cycles only
                    await self.run_complete_cycle()
                else:
                    # Run continuous orchestration
                    await self.run_complete_cycle()

                    # Small delay between iterations
                    await asyncio.sleep(2)

            self.logger.info("DONE: Orchestration completed")

        except Exception as e:
            self.logger.error(f"ðŸ’¥ Orchestration failed: {e}")
        finally:
            self.save_state()
            self.generate_final_report()

    def save_state(self):
        """Save current orchestration state"""
        state = {
            "timestamp": datetime.now().isoformat(),
            "current_iteration": self.current_iteration,
            "cycles_completed": self.cycles_completed,
            "system_state": self.system_state,
            "fitness_history": self.fitness_history[-20:],  # Last 20 entries
            "learned_patterns": self.learned_patterns,
            "command_history": self.command_history[-50:],  # Last 50 commands
            "consecutive_improvements": self.consecutive_improvements,
            "consecutive_degradations": self.consecutive_degradations
        }

        try:
            with open(self.state_file, 'w') as f:
                json.dump(state, f, indent=2)
            self.logger.info(f"DATA: State saved to {self.state_file}")
        except Exception as e:
            self.logger.error(f"Failed to save state: {e}")

    def generate_final_report(self):
        """Generate final orchestration report"""
        total_time = time.time() - self.start_time

        report = {
            "orchestration_summary": {
                "total_iterations": self.current_iteration,
                "cycles_completed": self.cycles_completed,
                "total_runtime_seconds": total_time,
                "final_fitness_score": self.system_state.get("fitness_score", 0),
                "commands_executed": len(self.command_history),
                "learned_patterns": len(self.learned_patterns)
            },
            "performance_metrics": {
                "average_cycle_time": total_time / max(1, self.cycles_completed),
                "commands_per_second": len(self.command_history) / max(1, total_time),
                "fitness_improvement": self._calculate_fitness_improvement(),
                "pattern_learning_efficiency": len([p for p in self.learned_patterns.values() if p > 1.0])
            },
            "command_statistics": self._calculate_command_statistics(),
            "final_state": self.system_state,
            "completion_reason": self._determine_completion_reason(),
            "recommendations": self._generate_recommendations()
        }

        report_file = self.logs_dir / "final_orchestration_report.json"
        try:
            with open(report_file, 'w') as f:
                json.dump(report, f, indent=2, default=str)
            self.logger.info(f"DATA: Final report saved to {report_file}")
        except Exception as e:
            self.logger.error(f"Failed to save final report: {e}")

        # Print summary to console
        self._print_final_summary(report)

    def _calculate_fitness_improvement(self):
        """Calculate overall fitness improvement"""
        if len(self.fitness_history) < 2:
            return 0.0

        initial_fitness = self.fitness_history[0]["fitness"]
        final_fitness = self.fitness_history[-1]["fitness"]

        return final_fitness - initial_fitness

    def _calculate_command_statistics(self):
        """Calculate command execution statistics"""
        stats = {}
        for cmd in self.command_history:
            cmd_name = cmd["command"]
            if cmd_name not in stats:
                stats[cmd_name] = {"executed": 0, "successful": 0}

            stats[cmd_name]["executed"] += 1
            if cmd["result"].get("success", False):
                stats[cmd_name]["successful"] += 1

        # Calculate success rates
        for cmd_name, data in stats.items():
            data["success_rate"] = data["successful"] / data["executed"]

        return stats

    def _determine_completion_reason(self):
        """Determine why orchestration completed"""
        if self.current_iteration >= self.max_iterations:
            return "max_iterations_reached"
        elif self.system_state.get("fitness_score", 0) >= self.fitness_threshold:
            return "fitness_threshold_achieved"
        elif self.consecutive_degradations >= self.max_consecutive_degradations:
            return "too_many_degradations"
        elif not self.running:
            return "graceful_shutdown"
        else:
            return "unknown"

    def _generate_recommendations(self):
        """Generate final recommendations"""
        recommendations = []

        final_fitness = self.system_state.get("fitness_score", 0)

        if final_fitness < 0.7:
            recommendations.append("System fitness needs improvement - focus on stability and testing")
        elif final_fitness < 0.9:
            recommendations.append("Good progress made - continue optimization and feature development")
        else:
            recommendations.append("Excellent system state - focus on innovation and advancement")

        # Add pattern-based recommendations
        if self.learned_patterns:
            best_pattern = max(self.learned_patterns, key=self.learned_patterns.get)
            recommendations.append(f"Most successful pattern: {best_pattern} - continue leveraging this approach")

        return recommendations

    def _print_final_summary(self, report):
        """Print final orchestration summary"""
        print("\n" + "="*80)
        print("AUTO-RECURSIVE CHAIN AI ORCHESTRATION COMPLETE")
        print("="*80)

        summary = report["orchestration_summary"]
        metrics = report["performance_metrics"]
        stats = report["command_statistics"]

        print(f"Total Iterations: {summary['total_iterations']}")
        print(f"Cycles Completed: {summary['cycles_completed']}")
        print(f"Commands Executed: {summary['commands_executed']}")
        print(f"Patterns Learned: {summary['learned_patterns']}")

        print("\nCOMMAND STATISTICS:")
        for cmd_name, data in stats.items():
            success_rate = data['success_rate'] * 100
            print(f"--- {cmd_name}: {success_rate:.1f}% success")
        print("\nFINAL RECOMMENDATIONS:")
        for rec in report["recommendations"]:
            print(f"   * {rec}")

        print(f"\nCompletion Reason: {report['completion_reason'].replace('_', ' ').title()}")
        print("="*80)


async def main():
    """Main orchestration entry point"""
    import argparse

    parser = argparse.ArgumentParser(description="Auto-Recursive Chain AI Orchestrator")
    parser.add_argument("--max-iterations", type=int, default=50,
                       help="Maximum number of iterations")
    parser.add_argument("--fitness-threshold", type=float, default=0.95,
                       help="Fitness threshold to achieve")
    parser.add_argument("--cycles-only", action="store_true",
                       help="Run complete cycles only")

    args = parser.parse_args()

    orchestrator = AutoRecursiveChainOrchestrator(
        max_iterations=args.max_iterations,
        fitness_threshold=args.fitness_threshold,
        cycles_only=args.cycles_only
    )

    await orchestrator.run_orchestration()


if __name__ == "__main__":
    asyncio.run(main())
